{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Root"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading Data & Functions #\n",
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "\n",
    "import matplotlib.pyplot as plt     # for plotting\n",
    "import numpy as np                  # for reshaping array manipulation\n",
    "import cv2                          # for image loading and colour conversion\n",
    "import tensorflow as tf             # for bulk image resize\n",
    "import glob\n",
    "import random\n",
    "import keras\n",
    "from sklearn import discriminant_analysis\n",
    "from sklearn import decomposition\n",
    "from sklearn.decomposition import IncrementalPCA\n",
    "import numpy\n",
    "from sklearn.manifold import TSNE\n",
    "import tensorflow as tf             # for bulk image resize\n",
    "import keras\n",
    "\n",
    "from keras.layers import Dense, Conv2D, BatchNormalization, Activation, AveragePooling2D, Input, Flatten, MaxPool2D, SpatialDropout2D\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, classification_report\n",
    "import seaborn as sns\n",
    "import random\n",
    "import copy\n",
    "\n",
    "import preprocessing as pre\n",
    "from sklearn.model_selection import train_test_split\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filepath"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = './Processed_Images_Square/'\n",
    "\n",
    "image_dimensions = (350,350,3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utility Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data import functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_subject_id_from_filename(fn):\n",
    "    try:\n",
    "        return pre.dog_num_to_name(int(fn.split('_')[0]))\n",
    "    except ValueError:\n",
    "        print(\"Error: Filename does not contain a valid subject ID:\", fn)\n",
    "        return None\n",
    "\n",
    "def load_directory(base_path):\n",
    "\n",
    "    # find all images in the directory\n",
    "    files = glob.glob(os.path.join(base_path, '*.jpg'))\n",
    "    x = []\n",
    "    y = []\n",
    "    \n",
    "    # loop through the images, loading them and extracting the subject ID\n",
    "    for f in files:\n",
    "        x.append(cv2.cvtColor(cv2.imread(f), cv2.COLOR_BGR2RGB) / 255.0)\n",
    "        y.append(get_subject_id_from_filename(os.path.basename(f)))\n",
    "        \n",
    "    return np.array(x), np.array(y)\n",
    "\n",
    "def load_data(base_path):\n",
    "    \n",
    "    # load training data\n",
    "    rawX, rawY = load_directory(base_path)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(rawX, rawY, test_size=0.2, random_state=42)\n",
    "    \n",
    "    return X_train, X_test, y_train, y_test\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_files(batch_size):\n",
    "    files = glob.glob(path + '*.jpg')\n",
    "\n",
    "    while True:\n",
    "        x = []\n",
    "        y = []\n",
    "        for i in range(batch_size):\n",
    "            f = random.choice(files)\n",
    "            x.append(cv2.cvtColor(cv2.imread(f), cv2.COLOR_BGR2RGB) / 255.0)\n",
    "            f = f.split('/')[-1]\n",
    "            dog_num = float(f.split('_')[0])\n",
    "            y.append(dog_num)\n",
    "\n",
    "        yield np.array(x), np.array(y)\n",
    "\n",
    "\n",
    "def gen_files_vec(batch_size):\n",
    "    image_generator = gen_files(batch_size)\n",
    "\n",
    "    while True:\n",
    "        x, y = next(image_generator)\n",
    "\n",
    "\n",
    "        yield vectorise(x), y\n",
    "\n",
    "def vectorise(images):\n",
    "    # use numpy's reshape to vectorise the data\n",
    "    return np.reshape(images, [len(images), -1])\n",
    "\n",
    "\n",
    "def plot_images(images, labels):\n",
    "    fig = plt.figure(figsize=[15, 18])\n",
    "    loop_count = 50\n",
    "    if len(images) < 50:\n",
    "        loop_count = len(images)\n",
    "    for i in range(loop_count):\n",
    "        ax = fig.add_subplot(8, 6, i + 1)\n",
    "        ax.imshow(images[i,:], cmap=plt.get_cmap('Greys'))\n",
    "        ax.set_title(labels[i])\n",
    "        ax.axis('off')\n",
    "\n",
    "\n",
    "def get_siamese_data(batch_size):\n",
    "\n",
    "    while True:\n",
    "        files = glob.glob(path + '*.jpg')\n",
    "\n",
    "        images = []\n",
    "        labels = []\n",
    "\n",
    "        for i in range(int(batch_size / 2)):\n",
    "            ## Get original dog\n",
    "\n",
    "            f = random.choice(files)\n",
    "            original_dog = cv2.cvtColor(cv2.imread(f), cv2.COLOR_BGR2RGB) / 255.0\n",
    "\n",
    "\n",
    "            ## Get matching pair\n",
    "            f = f.split('/')[-1]\n",
    "            dog_num = f.split('_')[0]\n",
    "\n",
    "            matching_breed_files = glob.glob(path + dog_num + '*.jpg')\n",
    "            matching_breed_files_without_original = copy.deepcopy(matching_breed_files)\n",
    "            matching_breed_files_without_original.remove(path + f)\n",
    "\n",
    "            matching_dog = random.choice(matching_breed_files)\n",
    "            pair_dog = cv2.cvtColor(cv2.imread(matching_dog), cv2.COLOR_BGR2RGB) / 255.0\n",
    "\n",
    "            images.append((original_dog, pair_dog))\n",
    "            labels.append(1.0)\n",
    "\n",
    "            ## Get non-matching pair\n",
    "            non_matching_breed_files = [x for x in files if x not in matching_breed_files]\n",
    "\n",
    "            non_matching_dog = random.choice(non_matching_breed_files)\n",
    "            non_pair_dog = cv2.cvtColor(cv2.imread(non_matching_dog), cv2.COLOR_BGR2RGB) / 255.0\n",
    "\n",
    "            images.append((original_dog, non_pair_dog))\n",
    "            labels.append(0.0)\n",
    "\n",
    "\n",
    "        yield np.array(images), np.array(labels)\n",
    "\n",
    "\n",
    "def plot_pairs(x, y):\n",
    "    fig = plt.figure(figsize=[25, 6])\n",
    "    for i in range(10):\n",
    "        ax = fig.add_subplot(2, 10, i*2 + 1)\n",
    "        ax.imshow(x[i][0,:])\n",
    "        ax.set_title('Pair ' + str(i) +'; Label: ' + str(y[i]))\n",
    "\n",
    "        ax = fig.add_subplot(2, 10, i*2 + 2)\n",
    "        ax.imshow(x[i][1,:])\n",
    "        ax.set_title('Pair ' + str(i) +'; Label: ' + str(y[i]))\n",
    "\n",
    "\n",
    "\n",
    "def plot_tsne(data_x, data_y):\n",
    "    tsne_embeddings = TSNE(random_state=4).fit_transform(data_x)\n",
    "    fig = plt.figure(figsize=[12, 12])\n",
    "    ax = fig.add_subplot(1, 1, 1)\n",
    "    ax.scatter(tsne_embeddings[:,0], tsne_embeddings[:,1], c = data_y.flatten());\n",
    "\n",
    "\n",
    "def cmc_to_top(cmc, verbose=True):\n",
    "    top1 = cmc[0]\n",
    "    top5 = cmc[4]\n",
    "    top10 = cmc[9]\n",
    "\n",
    "    if verbose:\n",
    "        print(f'Top 1: {top1}')\n",
    "        print(f'Top 5: {top5}')\n",
    "        print(f'Top 10: {top10}')\n",
    "\n",
    "    return top1, top5, top10\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'cat_num_to_names.txt'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m train_X, train_Y, test_X, test_Y \u001b[38;5;241m=\u001b[39m \u001b[43mload_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[11], line 25\u001b[0m, in \u001b[0;36mload_data\u001b[0;34m(base_path)\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mload_data\u001b[39m(base_path):\n\u001b[1;32m     23\u001b[0m     \n\u001b[1;32m     24\u001b[0m     \u001b[38;5;66;03m# load training data\u001b[39;00m\n\u001b[0;32m---> 25\u001b[0m     rawX, rawY \u001b[38;5;241m=\u001b[39m \u001b[43mload_directory\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbase_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     26\u001b[0m     X_train, X_test, y_train, y_test \u001b[38;5;241m=\u001b[39m train_test_split(rawX, rawY, test_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.2\u001b[39m, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m)\n\u001b[1;32m     28\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m X_train, X_test, y_train, y_test\n",
      "Cell \u001b[0;32mIn[11], line 18\u001b[0m, in \u001b[0;36mload_directory\u001b[0;34m(base_path)\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m f \u001b[38;5;129;01min\u001b[39;00m files:\n\u001b[1;32m     17\u001b[0m     x\u001b[38;5;241m.\u001b[39mappend(cv2\u001b[38;5;241m.\u001b[39mcvtColor(cv2\u001b[38;5;241m.\u001b[39mimread(f), cv2\u001b[38;5;241m.\u001b[39mCOLOR_BGR2RGB) \u001b[38;5;241m/\u001b[39m \u001b[38;5;241m255.0\u001b[39m)\n\u001b[0;32m---> 18\u001b[0m     y\u001b[38;5;241m.\u001b[39mappend(\u001b[43mget_subject_id_from_filename\u001b[49m\u001b[43m(\u001b[49m\u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpath\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbasename\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m     20\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m np\u001b[38;5;241m.\u001b[39marray(x), np\u001b[38;5;241m.\u001b[39marray(y)\n",
      "Cell \u001b[0;32mIn[11], line 3\u001b[0m, in \u001b[0;36mget_subject_id_from_filename\u001b[0;34m(fn)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_subject_id_from_filename\u001b[39m(fn):\n\u001b[1;32m      2\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m----> 3\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mpre\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdog_num_to_name\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mint\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplit\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m_\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      4\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m:\n\u001b[1;32m      5\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mError: Filename does not contain a valid subject ID:\u001b[39m\u001b[38;5;124m\"\u001b[39m, fn)\n",
      "File \u001b[0;32m~/Projects/CAB420-Assignment2/preprocessing.py:54\u001b[0m, in \u001b[0;36mdog_num_to_name\u001b[0;34m(num)\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdog_num_to_name\u001b[39m(num):\n\u001b[0;32m---> 54\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mdog_num_to_names.txt\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mr\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[1;32m     55\u001b[0m         c \u001b[38;5;241m=\u001b[39m csv\u001b[38;5;241m.\u001b[39mreader(f)\n\u001b[1;32m     57\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m row \u001b[38;5;129;01min\u001b[39;00m c:\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'cat_num_to_names.txt'"
     ]
    }
   ],
   "source": [
    "train_X, train_Y, test_X, test_Y = load_data(path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
